import os
import tqdm
import json
import math
import argparse

import numpy as np
import soundfile as sf
import tensorflow as tf

from scipy.signal import get_window

from config import Config as UnetConfig
from model import DiffWave
from model.vad import VAD
from model.clustering import get_mask
from utils.signal_processing import (
    compute_stft,
    compute_signal_from_stft,
    next_power_of_2
)


def main(args):

    # Activate CUDA if GPU id is given
    if args.gpu is not None:
        os.environ["CUDA_VISIBLE_DEVICES"] = str(args.gpu)
    else:
        os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

    model_path = os.path.join(".", "ckpt", args.model_name, args.model_name+"_BEST-SDR.ckpt-1")
    with open(os.path.join(".", "ckpt", args.model_name + ".json")) as f:
        unet_config = UnetConfig.load(json.load(f))

    diffwave = DiffWave(unet_config.model)
    diffwave.restore(model_path).expect_partial()
    mixture = tf.io.read_file(args.input_signal)
    mixture, _ =  tf.audio.decode_wav(mixture, desired_channels=1)
    mixture = tf.squeeze(mixture, axis=-1) / tf.reduce_max(mixture)

    TRIMS = args.batch_size
    output_voc = np.zeros(mixture.shape)
    hopsized_batch = int((TRIMS*22050) / 2)
    runs = math.floor(mixture.shape[0] / hopsized_batch)
    trim_low = 0
    for trim in tqdm.tqdm(np.arange((runs*2)-1)):
        trim_high = int(trim_low + (hopsized_batch*2))

        # Get input mixture spectrogram
        mix_trim = mixture[trim_low:trim_high]
        mix_mag, mix_phase = compute_stft(mix_trim[None], unet_config)
        new_len = next_power_of_2(mix_mag.shape[1])
        mix_mag_trim = mix_mag[:, :new_len, :]
        mix_phase_trim = mix_phase[:, :new_len, :]

        # Get and stack cold diffusion steps
        diff_feat = diffwave(mix_mag_trim, mode="train")
        diff_feat = tf.transpose(diff_feat, [1, 0, 2, 3])
        diff_feat_t = tf.squeeze(tf.reshape(diff_feat, [1, 8, diff_feat.shape[-2]*diff_feat.shape[-1]]), axis=0).numpy()

        # Normalize features, all energy curves having same range
        normalized_feat = []
        for j in np.arange(diff_feat_t.shape[1]):
            normalized_curve = diff_feat_t[:, j] / np.max(np.abs(diff_feat_t[:, j]))
            normalized_feat.append(normalized_curve)
        normalized_feat = np.array(normalized_feat, dtype=np.float32)

        # Compute mask using unsupervised clustering and reshape to magnitude spec shape
        mask = get_mask(normalized_feat, args.clusters, args.scheduler)
        mask = tf.reshape(mask, mix_mag_trim.shape)

        # Getting last step of computed features and applying mask
        diff_feat_t = tf.reshape(diff_feat_t[-1, :], mix_mag_trim.shape)
        output_signal = tf.math.multiply(diff_feat_t, mask)

        #Â Silence unvoiced regions
        output_signal = compute_signal_from_stft(output_signal, mix_phase_trim, unet_config)
        pred_audio = tf.squeeze(output_signal, axis=0).numpy()
        vad = VAD(pred_audio, sr=22050, nFFT=512, win_length=0.025, hop_length=0.01, theshold=0.99)
        if np.sum(vad) / len(vad) < 0.25:
            pred_audio = np.zeros(pred_audio.shape)

        # Get boundary
        boundary = None
        boundary = "start" if trim == 0 else None
        boundary = "end" if trim == runs-2 else None

        placehold_voc = np.zeros(output_voc.shape)
        placehold_voc[trim_low:trim_low+pred_audio.shape[0]] = pred_audio * get_window(pred_audio, boundary=boundary)
        output_voc += placehold_voc
        trim_low += pred_audio.shape[0] // 2

    output_voc = output_voc * (np.max(np.abs(mixture.numpy())) / np.max(np.abs(output_voc)))
    
    # Building intuitive filename with model config
    filefolder = os.path.join(args.input_signal.split("/")[:-1])
    filename = args.input_signal.split("/")[-1].split(".")[:-1]
    filename = filename[0] if len(filename) == 1 else ".".join(filename)
    filename = filename + "_" + str(args.clusters) + "_" + str(args.scheduler) + "pred_voc"
    sf.write(
        os.path.join(filefolder, filename + ".wav"),
        output_voc,
        22050) # Writing to file

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-name', default='saraga-8')
    parser.add_argument('--input_signal', default=None, type=str)
    parser.add_argument('--batch-size', default=6)
    parser.add_argument('--clusters', default=4, type=int)
    parser.add_argument('--scheduler', default=3., type=float)
    parser.add_argument('--gpu', default=None)
    args = parser.parse_args()
    main(args)
